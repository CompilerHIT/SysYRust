	.text
	.align	1
	.globl	sort
    .type sort, @function
sort:
    mv x76, x10
    mv x68, x11
    addiw x65, zero, 0
	j .LBB0_1
.LBB0_1:
    mv x64, x65
    addiw x67, x68, -1
    bge    x64, x67, .LBB0_2
	j .LBB0_3
.LBB0_2:
    ret
.LBB0_3:
    addiw x70, x64, 1
    mv x72, x70
	j .LBB0_4
.LBB0_4:
    mv x71, x72
    bge    x71, x68, .LBB0_5
	j .LBB0_6
.LBB0_5:
    addiw x66, x64, 1
    mv x65, x66
	j .LBB0_1
.LBB0_6:
    slliw x77, x64, 2
    add x78, x76, x77
	lw x75, 0(x78)
    slliw x80, x71, 2
    add x81, x76, x80
	lw x79, 0(x81)
    bge    x75, x79, .LBB0_7
	j .LBB0_8
.LBB0_7:
    addiw x73, x71, 1
    mv x72, x73
	j .LBB0_4
.LBB0_8:
    slliw x84, x64, 2
    add x85, x76, x84
	lw x83, 0(x85)
    slliw x87, x71, 2
    add x88, x76, x87
	lw x86, 0(x88)
    slliw x89, x64, 2
    add x90, x76, x89
	sw x86, 0(x90)
    slliw x91, x71, 2
    add x92, x76, x91
	sw x83, 0(x92)
	j .LBB0_7
	.text
	.align	1
	.globl	param16
    .type param16, @function
param16:
	ld x317, -64(sp)
	ld x316, -56(sp)
	ld x315, -48(sp)
	ld x314, -40(sp)
	ld x313, -32(sp)
	ld x312, -24(sp)
	ld x311, -16(sp)
	ld x310, -8(sp)
    mv x309, x17
    mv x308, x16
    mv x307, x15
    mv x306, x14
    mv x305, x13
    mv x304, x12
    mv x303, x11
    mv x302, x10
    addi x301, x2, 64
	sw x302, 0(x301)
	sw x303, 4(x301)
	sw x304, 8(x301)
	sw x305, 12(x301)
	sw x306, 16(x301)
	sw x307, 20(x301)
	sw x308, 24(x301)
	sw x309, 28(x301)
	sw x310, 32(x301)
	sw x311, 36(x301)
	sw x312, 40(x301)
	sw x313, 44(x301)
	sw x314, 48(x301)
	sw x315, 52(x301)
	sw x316, 56(x301)
	sw x317, 60(x301)
    addiw x318, zero, 16
    mv x11, x318
    addiw x319, zero, 0
    slliw x321, x319, 2
    add x320, x301, x321
    mv x10, x320
	call sort
	lw x322, 0(x301)
	lw x323, 4(x301)
	lw x324, 8(x301)
	lw x325, 12(x301)
	lw x326, 16(x301)
	lw x327, 20(x301)
	lw x328, 24(x301)
	lw x329, 28(x301)
	lw x330, 32(x301)
	lw x331, 36(x301)
	lw x332, 40(x301)
	lw x333, 44(x301)
	lw x334, 48(x301)
	lw x335, 52(x301)
	lw x336, 56(x301)
	lw x337, 60(x301)
	sd x317, -200(sp)
	sd x316, -192(sp)
	sd x315, -184(sp)
	sd x314, -176(sp)
	sd x313, -168(sp)
	sd x312, -160(sp)
	sd x311, -152(sp)
	sd x310, -144(sp)
	sd x309, -136(sp)
	sd x308, -128(sp)
	sd x307, -120(sp)
	sd x306, -112(sp)
	sd x305, -104(sp)
	sd x304, -96(sp)
	sd x303, -88(sp)
	sd x302, -80(sp)
	sd x337, -72(sp)
	sd x336, -64(sp)
	sd x335, -56(sp)
	sd x334, -48(sp)
	sd x333, -40(sp)
	sd x332, -32(sp)
	sd x331, -24(sp)
	sd x330, -16(sp)
    mv x17, x329
    mv x16, x328
    mv x15, x327
    mv x14, x326
    mv x13, x325
    mv x12, x324
    mv x11, x323
    mv x10, x322
	call param32_rec
    mv x338, x10
    mv x10, x338
    ret
	.text
	.align	1
	.globl	main
    .type main, @function
main:
	call getint
    mv x339, x10
	call getint
    mv x340, x10
	call getint
    mv x341, x10
	call getint
    mv x342, x10
	call getint
    mv x343, x10
	call getint
    mv x344, x10
	call getint
    mv x345, x10
	call getint
    mv x346, x10
	call getint
    mv x347, x10
	call getint
    mv x348, x10
	call getint
    mv x349, x10
	call getint
    mv x350, x10
	call getint
    mv x351, x10
	call getint
    mv x352, x10
	call getint
    mv x353, x10
	call getint
    mv x354, x10
	sd x354, -72(sp)
	sd x353, -64(sp)
	sd x352, -56(sp)
	sd x351, -48(sp)
	sd x350, -40(sp)
	sd x349, -32(sp)
	sd x348, -24(sp)
	sd x347, -16(sp)
    mv x17, x346
    mv x16, x345
    mv x15, x344
    mv x14, x343
    mv x13, x342
    mv x12, x341
    mv x11, x340
    mv x10, x339
	call param16
    mv x355, x10
    la x356, .LC1
	sw x355, 0(x356)
    addiw x358, zero, 1
	j .LBB4_1
.LBB4_1:
    mv x357, x358
    addiw x361, zero, 32
    bge    x357, x361, .LBB4_2
	j .LBB4_3
.LBB4_2:
    addiw x362, zero, 62
    slliw x364, x362, 2
    add x363, x356, x364
	sd x363, -200(sp)
    addiw x365, zero, 60
    slliw x367, x365, 2
    add x366, x356, x367
	sd x366, -192(sp)
    addiw x368, zero, 58
    slliw x370, x368, 2
    add x369, x356, x370
	sd x369, -184(sp)
    addiw x371, zero, 56
    slliw x373, x371, 2
    add x372, x356, x373
	sd x372, -176(sp)
    addiw x374, zero, 54
    slliw x376, x374, 2
    add x375, x356, x376
	sd x375, -168(sp)
    addiw x377, zero, 52
    slliw x379, x377, 2
    add x378, x356, x379
	sd x378, -160(sp)
    addiw x380, zero, 50
    slliw x382, x380, 2
    add x381, x356, x382
	sd x381, -152(sp)
    addiw x383, zero, 48
    slliw x385, x383, 2
    add x384, x356, x385
	sd x384, -144(sp)
    addiw x386, zero, 46
    slliw x388, x386, 2
    add x387, x356, x388
	sd x387, -136(sp)
    addiw x389, zero, 44
    slliw x391, x389, 2
    add x390, x356, x391
	sd x390, -128(sp)
    addiw x392, zero, 42
    slliw x394, x392, 2
    add x393, x356, x394
	sd x393, -120(sp)
    addiw x395, zero, 40
    slliw x397, x395, 2
    add x396, x356, x397
	sd x396, -112(sp)
    addiw x398, zero, 38
    slliw x400, x398, 2
    add x399, x356, x400
	sd x399, -104(sp)
    addiw x401, zero, 36
    slliw x403, x401, 2
    add x402, x356, x403
	sd x402, -96(sp)
    addiw x404, zero, 34
    slliw x406, x404, 2
    add x405, x356, x406
	sd x405, -88(sp)
    addiw x407, zero, 32
    slliw x409, x407, 2
    add x408, x356, x409
	sd x408, -80(sp)
    addiw x410, zero, 30
    slliw x412, x410, 2
    add x411, x356, x412
	sd x411, -72(sp)
    addiw x413, zero, 28
    slliw x415, x413, 2
    add x414, x356, x415
	sd x414, -64(sp)
    addiw x416, zero, 26
    slliw x418, x416, 2
    add x417, x356, x418
	sd x417, -56(sp)
    addiw x419, zero, 24
    slliw x421, x419, 2
    add x420, x356, x421
	sd x420, -48(sp)
    addiw x422, zero, 22
    slliw x424, x422, 2
    add x423, x356, x424
	sd x423, -40(sp)
    addiw x425, zero, 20
    slliw x427, x425, 2
    add x426, x356, x427
	sd x426, -32(sp)
    addiw x428, zero, 18
    slliw x430, x428, 2
    add x429, x356, x430
	sd x429, -24(sp)
    addiw x431, zero, 16
    slliw x433, x431, 2
    add x432, x356, x433
	sd x432, -16(sp)
    addiw x434, zero, 14
    slliw x436, x434, 2
    add x435, x356, x436
    mv x17, x435
    addiw x437, zero, 12
    slliw x439, x437, 2
    add x438, x356, x439
    mv x16, x438
    addiw x440, zero, 10
    slliw x442, x440, 2
    add x441, x356, x442
    mv x15, x441
    addiw x443, zero, 8
    slliw x445, x443, 2
    add x444, x356, x445
    mv x14, x444
    addiw x446, zero, 6
    slliw x448, x446, 2
    add x447, x356, x448
    mv x13, x447
    addiw x449, zero, 4
    slliw x451, x449, 2
    add x450, x356, x451
    mv x12, x450
    addiw x452, zero, 2
    slliw x454, x452, 2
    add x453, x356, x454
    mv x11, x453
    addiw x455, zero, 0
    slliw x457, x455, 2
    add x456, x356, x457
    mv x10, x456
	call param32_arr
    mv x458, x10
    mv x10, x458
	call putint
    addiw x459, zero, 10
    mv x10, x459
	call putch
    addiw x460, zero, 0
    mv x10, x460
    ret
.LBB4_3:
    addiw x461, x357, -1
    slliw x462, x461, 1
    addiw x463, x462, 1
    slliw x465, x463, 2
    add x466, x356, x465
	lw x464, 0(x466)
    addiw x467, x464, -1
    slliw x468, x357, 1
    slliw x469, x468, 2
    add x470, x356, x469
	sw x467, 0(x470)
    addiw x471, x357, -1
    slliw x472, x471, 1
    slliw x474, x472, 2
    add x475, x356, x474
	lw x473, 0(x475)
    addiw x476, x473, -2
    slliw x477, x357, 1
    addiw x478, x477, 1
    slliw x479, x478, 2
    add x480, x356, x479
	sw x476, 0(x480)
    addiw x359, x357, 1
    mv x358, x359
	j .LBB4_1
	.text
	.align	1
	.globl	param32_arr
    .type param32_arr, @function
param32_arr:
	ld x297, -192(sp)
	ld x292, -184(sp)
	ld x287, -176(sp)
	ld x282, -168(sp)
	ld x277, -160(sp)
	ld x272, -152(sp)
	ld x267, -144(sp)
	ld x262, -136(sp)
	ld x257, -128(sp)
	ld x252, -120(sp)
	ld x247, -112(sp)
	ld x242, -104(sp)
	ld x237, -96(sp)
	ld x232, -88(sp)
	ld x227, -80(sp)
	ld x222, -72(sp)
	ld x217, -64(sp)
	ld x212, -56(sp)
	ld x207, -48(sp)
	ld x202, -40(sp)
	ld x197, -32(sp)
	ld x192, -24(sp)
	ld x187, -16(sp)
	ld x182, -8(sp)
    mv x177, x17
    mv x172, x16
    mv x167, x15
    mv x162, x14
    mv x157, x13
    mv x152, x12
    mv x147, x11
    mv x143, x10
	lw x142, 0(x143)
	lw x144, 4(x143)
    addw x145, x142, x144
	lw x146, 0(x147)
    addw x148, x145, x146
	lw x149, 4(x147)
    addw x150, x148, x149
	lw x151, 0(x152)
    addw x153, x150, x151
	lw x154, 4(x152)
    addw x155, x153, x154
	lw x156, 0(x157)
    addw x158, x155, x156
	lw x159, 4(x157)
    addw x160, x158, x159
	lw x161, 0(x162)
    addw x163, x160, x161
	lw x164, 4(x162)
    addw x165, x163, x164
	lw x166, 0(x167)
    addw x168, x165, x166
	lw x169, 4(x167)
    addw x170, x168, x169
	lw x171, 0(x172)
    addw x173, x170, x171
	lw x174, 4(x172)
    addw x175, x173, x174
	lw x176, 0(x177)
    addw x178, x175, x176
	lw x179, 4(x177)
    addw x180, x178, x179
	lw x181, 0(x182)
    addw x183, x180, x181
	lw x184, 4(x182)
    addw x185, x183, x184
	lw x186, 0(x187)
    addw x188, x185, x186
	lw x189, 4(x187)
    addw x190, x188, x189
	lw x191, 0(x192)
    addw x193, x190, x191
	lw x194, 4(x192)
    addw x195, x193, x194
	lw x196, 0(x197)
    addw x198, x195, x196
	lw x199, 4(x197)
    addw x200, x198, x199
	lw x201, 0(x202)
    addw x203, x200, x201
	lw x204, 4(x202)
    addw x205, x203, x204
	lw x206, 0(x207)
    addw x208, x205, x206
	lw x209, 4(x207)
    addw x210, x208, x209
	lw x211, 0(x212)
    addw x213, x210, x211
	lw x214, 4(x212)
    addw x215, x213, x214
	lw x216, 0(x217)
    addw x218, x215, x216
	lw x219, 4(x217)
    addw x220, x218, x219
	lw x221, 0(x222)
    addw x223, x220, x221
	lw x224, 4(x222)
    addw x225, x223, x224
	lw x226, 0(x227)
    addw x228, x225, x226
	lw x229, 4(x227)
    addw x230, x228, x229
	lw x231, 0(x232)
    addw x233, x230, x231
	lw x234, 4(x232)
    addw x235, x233, x234
	lw x236, 0(x237)
    addw x238, x235, x236
	lw x239, 4(x237)
    addw x240, x238, x239
	lw x241, 0(x242)
    addw x243, x240, x241
	lw x244, 4(x242)
    addw x245, x243, x244
	lw x246, 0(x247)
    addw x248, x245, x246
	lw x249, 4(x247)
    addw x250, x248, x249
	lw x251, 0(x252)
    addw x253, x250, x251
	lw x254, 4(x252)
    addw x255, x253, x254
	lw x256, 0(x257)
    addw x258, x255, x256
	lw x259, 4(x257)
    addw x260, x258, x259
	lw x261, 0(x262)
    addw x263, x260, x261
	lw x264, 4(x262)
    addw x265, x263, x264
	lw x266, 0(x267)
    addw x268, x265, x266
	lw x269, 4(x267)
    addw x270, x268, x269
	lw x271, 0(x272)
    addw x273, x270, x271
	lw x274, 4(x272)
    addw x275, x273, x274
	lw x276, 0(x277)
    addw x278, x275, x276
	lw x279, 4(x277)
    addw x280, x278, x279
	lw x281, 0(x282)
    addw x283, x280, x281
	lw x284, 4(x282)
    addw x285, x283, x284
	lw x286, 0(x287)
    addw x288, x285, x286
	lw x289, 4(x287)
    addw x290, x288, x289
	lw x291, 0(x292)
    addw x293, x290, x291
	lw x294, 4(x292)
    addw x295, x293, x294
	lw x296, 0(x297)
    addw x298, x295, x296
	lw x299, 4(x297)
    addw x300, x298, x299
    mv x10, x300
    ret
	.text
	.align	1
	.globl	param32_rec
    .type param32_rec, @function
param32_rec:
    mv x138, x13
    mv x137, x14
    mv x136, x15
    mv x135, x16
    mv x134, x17
	ld x133, -8(sp)
	ld x132, -16(sp)
	ld x131, -24(sp)
	ld x130, -32(sp)
	ld x129, -40(sp)
	ld x128, -48(sp)
	ld x127, -56(sp)
	ld x126, -64(sp)
	ld x125, -72(sp)
	ld x124, -80(sp)
	ld x123, -88(sp)
	ld x122, -96(sp)
	ld x121, -104(sp)
	ld x120, -112(sp)
	ld x119, -120(sp)
	ld x118, -128(sp)
	ld x117, -136(sp)
	ld x116, -144(sp)
	ld x115, -152(sp)
	ld x114, -160(sp)
	ld x113, -168(sp)
	ld x112, -176(sp)
	ld x111, -184(sp)
	ld x110, -192(sp)
    mv x99, x12
    mv x98, x11
    mv x94, x10
    addiw x95, zero, 0
    bne    x94, x95, .LBB1_1
	j .LBB1_2
.LBB1_1:
    addiw x96, x94, -1
    addw x97, x98, x99
    li x103, 288737297
    mul x104, x103, x97
    srli x105, x104, 32
    sraiw x106, x105, 26
    srliw x107, x97, 31
    addw x101, x107, x106
    li x108, 998244353
    mulw x102, x101, x108
    subw x100, x97, x102
    addiw x109, zero, 0
	sd x109, -200(sp)
	sd x110, -192(sp)
	sd x111, -184(sp)
	sd x112, -176(sp)
	sd x113, -168(sp)
	sd x114, -160(sp)
	sd x115, -152(sp)
	sd x116, -144(sp)
	sd x117, -136(sp)
	sd x118, -128(sp)
	sd x119, -120(sp)
	sd x120, -112(sp)
	sd x121, -104(sp)
	sd x122, -96(sp)
	sd x123, -88(sp)
	sd x124, -80(sp)
	sd x125, -72(sp)
	sd x126, -64(sp)
	sd x127, -56(sp)
	sd x128, -48(sp)
	sd x129, -40(sp)
	sd x130, -32(sp)
	sd x131, -24(sp)
	sd x132, -16(sp)
    mv x17, x133
    mv x16, x134
    mv x15, x135
    mv x14, x136
    mv x13, x137
    mv x12, x138
    mv x11, x100
    mv x10, x96
	call param32_rec
    mv x139, x10
    mv x141, x139
	j .LBB1_3
.LBB1_2:
    mv x141, x98
	j .LBB1_3
.LBB1_3:
    mv x140, x141
    mv x10, x140
    ret